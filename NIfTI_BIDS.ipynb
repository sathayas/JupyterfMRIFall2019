{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:center'>\n",
    "PSY 394U <b>Methods for fMRI</b>, Fall 2018\n",
    "\n",
    "\n",
    "<img style='width: 300px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Placebo_Left.png?raw=true' alt='brain blobs'/>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style='text-align:center; font-size:40px; margin-bottom: 30px;'><b>Neuroimaging data structure</b></p>\n",
    "\n",
    "<p style='text-align:center; font-size:18px; margin-bottom: 32px;'><b>September 24, 2018</b></p>\n",
    "\n",
    "<hr style='height:5px;border:none' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICOM to NIfTI conversion\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "MRI scanners typically produce image data in their own format. The most common image data format from MRI scanners is DICOM. However, most neuroimaging analysis tools are not designed to handle DICOM images. Thus, first you need to convert DICOM to NIfTI format images. \n",
    "\n",
    "I do not cover details here, since this conversion is something you only need to do once, and there are a number of tools to do so. Here are some popular tools to convert DICOM images to NIfTI images:\n",
    "\n",
    "* **dcm2niix**: (https://www.nitrc.org/plugins/mwiki/index.php/dcm2nii:MainPage)\n",
    "* **mri_convert**: (https://surfer.nmr.mgh.harvard.edu/fswiki/mri_convert)\n",
    "* **spm12** (Siemens only): (https://www.fil.ion.ucl.ac.uk/spm/software/spm12/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIfTI file format (`.nii`)\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is NIfTI format?\n",
    "\n",
    "**NIfTI** stands for *Neuroimaging Informatics Technology Initiative*, with **`.nii`** extension. Before the NIfTI format, the predominant file format for neuroimaging research was the Analyze format (with `.hdr` and `.img` files). However, different software packages embedded different information in image data files, and consequently image data were not truly compatible once it has been processed in a certain software package. To address this issue, the NIfTI format was introduced. Today, most neuroimaging data are in the NIfTI format.\n",
    "\n",
    "A NIfTI file consists of the header information (first 348 Bytes) and the image data (the rest of the file).\n",
    "\n",
    "## NIfTI header\n",
    "\n",
    "A typical NIfTI header includes a number of fields describing information regarding the image. Let's take a look at an example from an fMRI image. I am using the same file from the previous class (`ds102` data set, subject 26). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<ViewHeader.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  4  64  64  40 146   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : int16\n",
      "bitpix          : 16\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 3. 3. 4. 2. 0. 0. 0.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'FSL4.0'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : -94.5\n",
      "qoffset_y       : -108.95783\n",
      "qoffset_z       : -67.87952\n",
      "srow_x          : [  3.    0.    0.  -94.5]\n",
      "srow_y          : [   0.         3.         0.      -108.95783]\n",
      "srow_z          : [  0.        0.        4.      -67.87952]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "# Directory where your data set resides. This needs to be customized\n",
    "#dataDir = '/home/satoru/Teaching/fMRI_Fall_2018/Data/ds102'\n",
    "dataDir = '/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds102'\n",
    "\n",
    "\n",
    "# reading in the fMRI data array\n",
    "f_fMRI = os.path.join(dataDir,'sub-26/func/sub-26_task-flanker_run-2_bold.nii.gz')\n",
    "fMRI = nib.load(f_fMRI)   # image object\n",
    "\n",
    "# priting out the header information\n",
    "hdr_fMRI = fMRI.header\n",
    "print(hdr_fMRI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of methods associated with the NIfTI header that provide you information you may be interested. First, the image dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 40, 146)\n"
     ]
    }
   ],
   "source": [
    "# image dimension\n",
    "print(hdr_fMRI.get_data_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first 3 elements (**`64  64  40`**) show the number of voxels in the x, y, and z dimensions. The 4th element (**`146`**) is the number of time points in this fMRI time series. \n",
    "\n",
    "Next, data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int16\n"
     ]
    }
   ],
   "source": [
    "# data type\n",
    "print(hdr_fMRI.get_data_dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that, the data format for each voxel value is **`int16`**, or 16-bit integer. If you ever want to change the data type to another format, you can use the **`set_data_dtype()`** method associated with the header. For example,\n",
    "```python\n",
    "hdr_fMRI.set_data_dtype('float32')\n",
    "```\n",
    "sets the data type to be 32-bit float.\n",
    "\n",
    "The voxel size can be viewed by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.0, 3.0, 4.0, 2.0)\n"
     ]
    }
   ],
   "source": [
    "# voxel size\n",
    "print(hdr_fMRI.get_zooms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first 3 elements correspond to voxel sizes in mm in x-, y-, and z-directions, respectively. The last element refers to the repetition time (TR, time between scans) in seconds.\n",
    "\n",
    "### Exercise\n",
    "1. **Header info, T1 image**. Get the image dimension, data type, and voxel size from the T1 image of a randomly selected subject from the data set `ds102`. Post the resulting information (rather than the code) on Canvas.\n",
    "2. **Header info, fMRI data, ds114**. Get the image dimension, data type, and voxel size from the fMRI data of a randomly selected subject from the data set `ds114`. Post the resulting information (rather than the code) on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 256, 256)\n",
      "int16\n",
      "(1.0, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# reading in the structural MRI header\n",
    "f_sMRI = os.path.join(dataDir,'sub-10/anat/sub-10_T1w.nii.gz')\n",
    "sMRI = nib.load(f_sMRI)\n",
    "hdr_sMRI = sMRI.header\n",
    "\n",
    "# image dimension\n",
    "print(hdr_sMRI.get_data_shape())\n",
    "\n",
    "# data type\n",
    "print(hdr_sMRI.get_data_dtype())\n",
    "\n",
    "# voxel size\n",
    "print(hdr_sMRI.get_zooms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful piece of information in the NIfTI header is the affine information. It is a 4x4 matrix that lets you transform the voxel coordinates. This is what the affine matrix looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<AffineInfo.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "# Directory where your data set resides. This needs to be customized\n",
    "dataDir = '/home/satoru/Teaching/fMRI_Fall_2018/Data/ds102'\n",
    "\n",
    "# reading in the T1 data array\n",
    "f_sMRI = os.path.join(dataDir,'sub-26/anat/sub-26_T1w.nii.gz')\n",
    "sMRI = nib.load(f_sMRI)\n",
    "X_sMRI = sMRI.get_data()\n",
    "\n",
    "# affine matrix\n",
    "print(sMRI.affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, although this information is embedded in the header, we use the **`affine`** method associated with the *image object*, not the *header*. So, why should we care about this matrix? This matrix lets you transform array indices into the voxel coordinates in the brain space. Say, you want to see where the voxel `[85, 110, 140]` is located in the brain space (in terms of mm). \n",
    "\n",
    "To do so, you create a vector with the desired indices, plus 1 as the fourth element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example voxel indices\n",
    "xyz = np.array([[85, 110, 140]])\n",
    "xyz1 = np.hstack([xyz,np.array([[1]])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you multiply this with the affine matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming array indices to brain space coordinate\n",
    "A = sMRI.affine\n",
    "brain_xyz = np.dot(A,xyz1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first 3 elements correspond to the voxel coordinate in the brain space, in terms of mm. You can verify this with an image viewer. For example, in FSL,\n",
    "\n",
    "<img style='width: 650px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Affine_Viewer.png?raw=true' alt='Affine viewer'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to transform the voxel coordinates in the brain space (in mm) to the corresponding array indices, simply finding the inverse of the affine matrix. For example, take the coordinate `[0, 0, 0]`mm in the brain space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxel coordinate in mm\n",
    "xyzmm = np.array([[0, 0, 0]])\n",
    "xyz1mm = np.hstack([xyzmm,np.array([[1]])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz1mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming brain space coordinate (in mm) to array indices\n",
    "invA = np.linalg.inv(A)\n",
    "voxel_xyz = np.dot(invA,xyz1mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can check with an image viewer.\n",
    "\n",
    "<img style='width: 650px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Affine_Inverse.png?raw=true' alt='Affine viewer'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this image is the raw data, thus the center of the image `[0, 0, 0]`(in the brain space) is at an arbitrary location. During the preprocessing, the center is usually placed in the anterior commissure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIfTI data matrix\n",
    "\n",
    "This portion of a NIfTI file consists of a series of 3D or 4D voxel intensities stored in a long sequence of numbers. There are several conventions to store voxel intensities such as:\n",
    "  * **RAS**\n",
    "      * First axis: x-axis left to **R**ight\n",
    "      * Second axis: y-axis posterior to **A**nterior\n",
    "      * Third axis: z-axis inferior to **S**uperior\n",
    "  * **LAS**\n",
    "      * First axis: x-axis right to **L**eft\n",
    "      * Second axis: y-axis posterior to **A**nterior\n",
    "      * Third axis: z-axis inferior to **S**uperior\n",
    "      \n",
    "Unless your data set consists of images acquired from different scanners with different protocols, you do not have to worry about how data are stored in a NIfTI file. Most image viewers and analysis software tools can display and process images in the desired orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radiological vs. Neurological\n",
    "\n",
    "One thing you have to deal with, in your analysis as well as when you read the neuroimaging literature, is the orientation how the brain is displayed. There are two conventions:\n",
    "  * Neurological: \n",
    "      * Patient's left is displayed on the left\n",
    "  * Radiological:\n",
    "      * Patient's left is displayed on the right\n",
    "      \n",
    "<img style='width: 400px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Affine_radio_neuro.jpg?raw=true' alt='Neurological or radiological'/>\n",
    "\n",
    "\n",
    "When you examine image data, make sure which side of the subject is displayed on which side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is BIDS?\n",
    "\n",
    "BIDS stands for Brain Imaging Data Structure. BIDS is a systematic way of organizing neurimaging data with a consistent structure. Before BIDS, each lab organized their neuroimaging data in their own way. This was a big obstacle in sharing data across different labs. Moreover, porting of any processing pipeline, from one lab to another, required a significant re-coding in order to accommodate different data organization. \n",
    "\n",
    "The complete specification of the BIDS is available from the [BIDS's web site](http://bids.neuroimaging.io/bids_spec.pdf). Here are highlights of BIDS:\n",
    "\n",
    "* Hierarchical organization of directories\n",
    "* Consistent naming of files and directories\n",
    "* Specific file formats\n",
    "\n",
    "## Hierarchical directory organization\n",
    "\n",
    "In BIDS, directories are organized in a hierarchical fashion. From the top,\n",
    "  * **Data set**. This is the directory containing all the data associated with a particular neuroimaging experiment.\n",
    "  * **Subject**. Each subject or animal in the experiment has a directory. All data pertaining to that subject are stored there.\n",
    "     * It should start with **`sub-`**, followed by a string identifying a subject.\n",
    "        * For example, **`sub-control01`**, **`sub-patient15`**, or simply **`sub-03`**.\n",
    "     * The subject number should be zero-padded. For example, **`01`** or **`001`** instead of **`1`**. This facilitates sorting of subjects according to their numbers.\n",
    "  * **Session** (if applicable). A session refers to a visit in a longitudinal study, or a scanning session in a multi-session experiment. If there is only one session in the experiment, then this can be disregarded. \n",
    "     * It should start with **`ses-`** followed by the string identifying each session.\n",
    "        * For example, **`ses-before`**, **`ses-time0`**, or **`ses-posttest`**.\n",
    "  * **Modality**. This is a directory containing imaging and other data files associated with a particular imaging modality (e.g., structural images (T1 weighted images), functional images, diffusion weighted images, MEG, PET).\n",
    "     * Suggested directory names are:\n",
    "        * **`anat`** Structural image data, modalities including T1-weighted, T2-weighted, FLAIR, and proton density.\n",
    "        * **`func`** Functional MRI data.\n",
    "        * **`dwi`** Diffusion weighted images.\n",
    "        * **`meg`** MEG (Magnetoencephalography)\n",
    "        \n",
    "***NB: Directory names are case sensitive. Use of lower case letters recommended.***\n",
    "\n",
    "### Example\n",
    "\n",
    "Here is the directory organization for the first two subjects for the `ds114` data set, viewed by the **`tree`** command.\n",
    "```\n",
    "../Data/ds114/\n",
    "|...\n",
    "|-- sub-01\n",
    "|   |-- ses-retest\n",
    "|   |   |-- anat\n",
    "|   |   |   `-- sub-01_ses-retest_T1w.nii.gz\n",
    "|   |   |-- dwi\n",
    "|   |   |   `-- sub-01_ses-retest_dwi.nii.gz\n",
    "|   |   `-- func\n",
    "|   |       |-- sub-01_ses-retest_task-covertverbgeneration_bold.nii.gz\n",
    "|   |       |...\n",
    "|   |       `-- sub-01_ses-retest_task-overtwordrepetition_bold.nii.gz\n",
    "|   `-- ses-test\n",
    "|       |-- anat\n",
    "|       |   `-- sub-01_ses-test_T1w.nii.gz\n",
    "|       |-- dwi\n",
    "|       |   `-- sub-01_ses-test_dwi.nii.gz\n",
    "|       `-- func\n",
    "|           |-- sub-01_ses-test_task-covertverbgeneration_bold.nii.gz\n",
    "|           |...\n",
    "|           `-- sub-01_ses-test_task-overtwordrepetition_bold.nii.gz\n",
    "|-- sub-02\n",
    "|   |-- ses-retest\n",
    "|   |   |-- anat\n",
    "|   |   |   `-- sub-02_ses-retest_T1w.nii.gz\n",
    "|   |   |-- dwi\n",
    "|   |   |   `-- sub-02_ses-retest_dwi.nii.gz\n",
    "|   |   `-- func\n",
    "|   |       |-- sub-02_ses-retest_task-covertverbgeneration_bold.nii.gz\n",
    "|   |       |...\n",
    "|   |       `-- sub-02_ses-retest_task-overtwordrepetition_bold.nii.gz\n",
    "|   `-- ses-test\n",
    "|       |-- anat\n",
    "|       |   `-- sub-02_ses-test_T1w.nii.gz\n",
    "|       |-- dwi\n",
    "|       |   `-- sub-02_ses-test_dwi.nii.gz\n",
    "|       `-- func\n",
    "|           |-- sub-02_ses-test_task-covertverbgeneration_bold.nii.gz\n",
    "|           |...\n",
    "|           `-- sub-02_ses-test_task-overtwordrepetition_bold.nii.gz\n",
    "|-- sub-03\n",
    "|...\n",
    "```\n",
    "\n",
    "In this study, each subject underwent two sessions (`test` and `retest`). Within each session, there are directories for structural MRI (`anat`), fMRI (`func`), and diffusion images (`dwi`).\n",
    "\n",
    "## Image data and how to name them\n",
    "\n",
    "The recommended image format for BIDS is NIfTI (`.nii`). It can be either uncompressed or gzipped (**`.nii.gz`**).\n",
    "\n",
    "### Structural image data naming convention (`anat`)\n",
    "\n",
    "A structural image data file should be named by following this convention:\n",
    "```\n",
    "sub-<participant_label>[_ses-<session_label>]_<modality_label>.nii[.gz]\n",
    "```\n",
    "Here, the elements are:\n",
    "  * **`sub-<participant_label>`**: Subject identifier, as explained above.\n",
    "  * **`ses-<session_label>`**: Session identifier, where applicable, as explained above. If there is only one session in the experiment, this can be disregarded.\n",
    "  * **`<modality_label>`**: Modality label. There are different labels:\n",
    "     * **`T1w`**: T1-weighted (typical structural MRI)\n",
    "     * **`T2w`**: T2-weighted\n",
    "     * **`PD`**: Proton density\n",
    "\n",
    "In addition to these, you can embed additional information to the file name such as acquisition parameters, contrast enhancement, reconstruction algorithms, and runs. You can find the additional information in the BIDS specification.\n",
    "\n",
    "***Examples***:\n",
    "```\n",
    "sub-01_ses-retest_T1w.nii.gz\n",
    "sub-10_T1w.nii.gz\n",
    "```\n",
    "\n",
    "### Functional image data naming convention (`func`)\n",
    "\n",
    "A functional image data file should be named by following this convention:\n",
    "```\n",
    "sub-<participant_label>[_ses-<session_label>]_task-<task_label>[_run-<index>]_bold.nii[.gz]\n",
    "```\n",
    "Here, the elements are:\n",
    "  * **`sub-<participant_label>`**: Subject identifier, as explained above.\n",
    "  * **`ses-<session_label>`**: Session identifier, where applicable, as explained above. If there is only one session in the experiment, this can be disregarded.\n",
    "  * **`task-<task_label>`**: Task identifier. Here, you need to name the task with a **`<task_label>`** consisting of letters and/or numbers (no special characters). \n",
    "     * Examples: `nback`, `stroop`, `fingertapping`, `rest`\n",
    "  * **`run-<index>`**: Run index. Say, you have multiple runs of the same task in your experiment, you can distinguish them by including the run index. A run can be indicated by a single number (no zero padding is necessary). If there is only one run, then you can ignore this.\n",
    "     * Examples: `run-1`, `run-2`\n",
    "     \n",
    "In addition to these, you can embed additional information to the file name. You can find the additional information in the BIDS specification.\n",
    "\n",
    "***Examples***\n",
    "```\n",
    "sub-07_ses-test_task-overtverbgeneration_bold.nii.gz\n",
    "sub-12_task-flanker_run-2_bold.nii.gz\n",
    "```\n",
    "\n",
    "### Diffusion image data naming convention (`dwi`)\n",
    "\n",
    "Although we do not talk about diffusion images, it is common to acquire diffusion images during an fMRI experiment. Here is how you can name data files:\n",
    "```\n",
    "sub-<participant_label>[_ses-<session_label>][_run-<index>]_dwi.nii[.gz]\n",
    "sub-<participant_label>[_ses-<session_label>][_run-<index>]_dwi.bval\n",
    "sub-<participant_label>[_ses-<session_label>][_run-<index>]_dwi.bvec\n",
    "```\n",
    "\n",
    "Here, the elements for the name has already been explained above. One thing to note here is that you need, in addition to the NIfTI image, data files describing diffusion parameters. The **`.bvec`** file contains diffusion directions, and the **`.bval`** file contains diffusion values. The `.bvec` and `.bval` follow the format specified by FSL. For details, I refer you to the BIDS specification document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other file formats and files\n",
    "\n",
    "### Tabular files (`.tsv`)\n",
    "\n",
    "If you want to include information in a tabular format, you need to use the tab separated value format (**`.tsv`**). A `.tsv` file is easily *readable* by humans. It is ideal to store information such as participant information or task timing information. \n",
    "\n",
    "***Examples***\n",
    "\n",
    "Task information (see below for details):\n",
    "```\n",
    "onset  duration  response_time   correct   stop_trial   go_trial\n",
    "200    20        0               n/a       n/a          n/a\n",
    "```\n",
    "\n",
    "\n",
    "Participant information (**`participants.tsv`**): (Located under the data set directory)\n",
    "```\n",
    "participant_id\t gender\t  age\n",
    "sub-01\t         F\t      21.94\n",
    "sub-02\t         M\t      22.79\n",
    "sub-03\t         M\t      19.65\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "### JSON dictionary files (`.json`)\n",
    "\n",
    "A JSON (JavaScript Object Notation) file contains pairs of keys and values, just as a dictionary in python. JSON files can be used to describe details about data sets, sessions, runs, tasks, or imaging parameters. There are a number of JSON format files with specific fields (or keys). \n",
    "\n",
    "***Examples***\n",
    "\n",
    "Image acquisition parameters:\n",
    "```\n",
    "{\n",
    "\t\"RepetitionTime\": 2.5,\n",
    "\t\"Manufacturer\": \"Siemens\",\n",
    "\t\"ManufacturerModelName\": \"Allegra\",\n",
    "\t\"MagneticFieldStrength\": 3.0,\n",
    "\t\"ScanningSequence\": \"MPRAGE\",\n",
    "\t\"MRAcquisitionType\": \"3D\",\n",
    "\t\"EchoTime\": 0.00393,\n",
    "\t\"InversionTime\": 0.90,\n",
    "\t\"FlipAngle\": 8.0\n",
    "}\n",
    "```\n",
    "\n",
    "Task description:\n",
    "```\n",
    "{\n",
    "    \"EchoTime\": 0.05,\n",
    "    \"FlipAngle\": 90,\n",
    "    \"RepetitionTime\": 5.0,\n",
    "    \"SliceTiming\": [\n",
    "        0.0,\n",
    "        1.2499999999999998,\n",
    "        0.08333333333333333,\n",
    "        ...\n",
    "        1.1666666666666665,\n",
    "        2.416666666666665\n",
    "    ],\n",
    "    \"TaskName\": \"overt_verb_generation\"\n",
    "}\n",
    "```\n",
    "\n",
    "**What is a dictionary?** A dictionary is like a list. But unlike a list whose items are indexed by a number, we can refer items in a dictionary with keys. Here is an example of a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookInfo = {'Author':'Sweigart, Al',\n",
    "            'Title':'Automate the Boring Stuff with Python',\n",
    "            'Publisher':'No Starch Press',\n",
    "            'Year': 2015,\n",
    "            'Pages':503}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the dictionary consists of a **key** and a **value** separated by a colon (`:`). You can use a key to access the value of the corresponding item. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookInfo['Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookInfo['Pages']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can just get keys, to see what fields are in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookInfo.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, *why should we care about dictionaries?* Sometimes it makes sense to organize multiple properties of an object / individual as a single entity, as opposed to a collection of separate variables. JSON format is a universal format to describe dictionary-like information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required files\n",
    "\n",
    "Some data files (`.tsv` or `.json`) are required by BIDS.\n",
    "\n",
    "#### Data set description (`dataset_description.json`)\n",
    "This is a JSON file located under the main data set directory, describing the data set. The following are the fields for this file:\n",
    "\n",
    "  * **`Name`**: *REQUIRED.* Name of the dataset.\n",
    "  * **`BIDSVersion`**: *REQUIRED.* The version of the BIDS standard that was used. FYI, this particular note is base on BIDS version **1.1.1**. \n",
    "  * **`Authors`**:  *OPTIONAL.* List of individuals who contributed to the creation/curation of       ReferencesAndLinks OPTIONAL. List of references to publication that contain information on the dataset, or links.\n",
    "  * **`DatasetDOI`**: *OPTIONAL.* The Document Object Identifier of the dataset (not the\n",
    "corresponding paper).\n",
    "\n",
    "There are other recommended and optional fields. You can find more details in the BIDS specification document.\n",
    "\n",
    "***Example***\n",
    "```\n",
    "{\n",
    "    \"Name\":\"Flanker task (event-related)\",\n",
    "    \"BIDSVersion\":\"1.0.0rc3\",\n",
    "    \"License\":\"PDDL\",\n",
    "    \"Authors\":[\"Kelly AMC\",\"Uddin LQ\",\"Biswal BB\",\"Castellanos FX\",\"Milham MP\"],\n",
    "    \"HowToAcknowledge\":\"This data was obtained from the OpenfMRI database. Its accessio\n",
    "n number is ds000102\",\n",
    "    \"ReferencesAndLinks\":[\"http://www.ncbi.nlm.nih.gov/pubmed/20974260\",\"http://www.ncbi.nlm.nih.gov/pubmed/20079856\",\"http://www.ncbi.nlm.nih.gov/pubmed/17919929\"]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Task events (`.tsv`)\n",
    "\n",
    "A `.tsv` file describing task events is required for an fMRI data. This file contains the onset time and duration of ALL trials during the fMRI acquisition. The file has to have the following columns:\n",
    "\n",
    "  * **`onset`**: *REQUIRED.* Onset (in seconds) of the event measured from the beginning of the acquisition of the first volume in the corresponding task imaging data file. *If any acquired scans have been discarded before forming the imaging data file, ensure that a time of 0 corresponds to the first image stored. In other words negative numbers in “onset” are allowed.*\n",
    "  * **`duration`**: *REQUIRED.* Duration of the event (measured from onset) in seconds. Must always be either zero or positive. A \"duration\" value of zero implies that the delta function or event is so short as to be effectively modeled as an impulse.\n",
    "  * **`trial_type`**: *OPTIONAL.* Primary categorization of each trial to identify them as instances of the experimental conditions. \n",
    "     * For example: for a response inhibition task, it could take on values \"go\" and \"no-go\" to refer to response initiation and response inhibition experimental conditions.\n",
    "  * **`response_time`**: *OPTIONAL.* Response time measured in seconds. A negative response time can be used to represent preemptive responses and “n/a” denotes a missed response.\n",
    "  * **`stim_file`**: *OPTIONAL.* Represents the location of the stimulus file (image, video, sound etc.) presented at the given onset time. \n",
    "\n",
    "Additional columns can be added to facilitate organization of task event information.\n",
    "\n",
    "\n",
    "The task events file follows the **inheritance principle** of BIDS. The file should be placed under each subject/session's `func` directory. However, if the information is identical across sessions/subjects, it can be placed in a parent directory. As for the location and naming of the task events file:\n",
    "  * The task events `.tsv` file should be placed in the same directory as the corresponding fMRI file, with the name\n",
    "```\n",
    "sub-<participant_label>[_ses-<session_label>]_task-<task_label>[_run-<index>]_events.tsv\n",
    "```\n",
    "\n",
    "  * If the task events file is identical across runs, or there is only one run, then you only need one `.tsv` file\n",
    "```\n",
    "sub-<participant_label>[_ses-<session_label>]_task-<task_label>_events.tsv\n",
    "```\n",
    "\n",
    "  * If the task events file is identical across sessions and across runs, then the `.tsv` file can be named as\n",
    "```\n",
    "sub-<participant_label>_task-<task_label>_events.tsv\n",
    "```\n",
    "and placed under the **subject's directory**.\n",
    "\n",
    "  * If the task events file is identical across subjects, across sessions, and across runs, then the `.tsv` file can be named as\n",
    "```\n",
    "task-<task_label>_events.tsv\n",
    "```\n",
    "and placed under the **data set directory**.\n",
    "\n",
    "\n",
    "\n",
    "***Examples***\n",
    "\n",
    "```\n",
    "onset\tduration\tweight\ttrial_type\n",
    "10\t    15.0\t    1\t    Finger\n",
    "40\t    15.0\t    1\t    Foot\n",
    "70\t    15.0\t    1\t    Lips\n",
    "...\n",
    "```\n",
    "\n",
    "```\n",
    "onset   duration    trial_type   response_time   stim_file\n",
    "1.2     0.6         go           1.435           images/red_square.jpg\n",
    "5.6     0.6         stop         1.739           images/blue_square.jpg\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Optional, but useful files\n",
    "\n",
    "The following are optional but useful files. I do not explain details here, so please consult the BIDS specification documentation for more details.\n",
    "\n",
    "#### `participants.tsv`, `participants.json`\n",
    "**Purpose**: To list participants and their information (`.tsv`). Any additional information can be stored in the accompanying JSON file (`.json`).\n",
    "**Location**: Under the data set directory\n",
    "**Examples**:\n",
    "\n",
    "`participants.tsv`\n",
    "```\n",
    "participant_id\tdominant_hand\n",
    "sub-01\t        left\n",
    "sub-02\t        right\n",
    "sub-03\t        right\n",
    "...\n",
    "```\n",
    "\n",
    "#### Image meta information\n",
    "Information associated with image acquisition (TR, flip angle, slice timing, etc.) can be found in the image meta information file (`.json`). The file name (except the extension) should be identical to the corresponding image (`.nii`) file. However, the **inheritance principle** applies here as well; if the imaging parameters are identical, you may find only one meta information file (`.json`) for each image type under the data set directory.\n",
    "\n",
    "***Examples***\n",
    "\n",
    "T1-weighted meta information:\n",
    "```\n",
    "{\n",
    "\t\"RepetitionTime\": 2.5,\n",
    "\t\"Manufacturer\": \"Siemens\",\n",
    "\t\"ManufacturerModelName\": \"Allegra\",\n",
    "\t\"MagneticFieldStrength\": 3.0,\n",
    "\t\"ScanningSequence\": \"MPRAGE\",\n",
    "\t\"MRAcquisitionType\": \"3D\",\n",
    "\t\"EchoTime\": 0.00393,\n",
    "\t\"InversionTime\": 0.90,\n",
    "\t\"FlipAngle\": 8.0\n",
    "}\n",
    "```\n",
    "\n",
    "fMRI meta information for a certain task:\n",
    "```\n",
    "{\n",
    "    \"EchoTime\": 0.05,\n",
    "    \"FlipAngle\": 90,\n",
    "    \"RepetitionTime\": 2.5,\n",
    "    \"SliceTiming\": [\n",
    "        0.0,\n",
    "        1.2499999999999998,\n",
    "        0.08333333333333333,\n",
    "        ...\n",
    "        2.333333333333332,\n",
    "        1.1666666666666665,\n",
    "        2.416666666666665\n",
    "    ],\n",
    "    \"TaskName\": \"finger_foot_lips\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Task events meta information (`.json`)\n",
    "In addition to the task events information, additional meta information can be provided as a JSON file. Its name and location should be identical to the task events `.tsv` file, except the extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling data with `pybids`\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pybids` library provides some functionalities to query a BIDS data set, enabling you to access data files and meta data.\n",
    "\n",
    "## `BIDSLayout` for simple queries\n",
    "\n",
    "You can query information from a BIDS data set by creating a **layout** object. A layout object simplifies accessing the content of a BIDS data set so that you don't have to scroll a long list of files and directories manually!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<ExtractBIDSInfo.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bids.grabbids import BIDSLayout\n",
    "\n",
    "\n",
    "# Directory where your data set resides. This needs to be customized.\n",
    "# For this exercise, lets use ds114 data set\n",
    "dataDir = '/home/satoru/Teaching/fMRI_Fall_2018/Data/ds114'\n",
    "\n",
    "# Creating the layout object for this BIDS data set\n",
    "layout = BIDSLayout(dataDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a layout object is created. So let's see some info associated with this data set. First, a list of subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects\n",
    "subjList = layout.get_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the prefix `sub-` has been automatically removed. \n",
    "\n",
    "Next, sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessions\n",
    "sesList = layout.get_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sesList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the prefix `ses-` has been automatically removed. \n",
    "\n",
    "Next, data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modalities\n",
    "modList = layout.get_modalities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, different tasks under `func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks\n",
    "taskList = layout.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there multiple runs? We shall see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs\n",
    "runList = layout.get_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing is returned, meaning that there is only one run for this data set.\n",
    "\n",
    "You can also generate a list of data you are interested. For example, we can make a list of all fMRI data for subject `01` by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all fMRI data for subject 01\n",
    "fMRI_sub01 = layout.get(subject='01', \n",
    "                        type='bold', \n",
    "                        extensions=['nii', 'nii.gz'],\n",
    "                        return_type='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fMRI_sub01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can focus just on `test` session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets focus on test session\n",
    "fMRI_sub01_test = layout.get(subject='01', \n",
    "                             session='test',\n",
    "                             type='bold', \n",
    "                             extensions=['nii', 'nii.gz'],\n",
    "                             return_type='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fMRI_sub01_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, we are interested in meta data associated with the covert verb generation task (`covertverbgeneration`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of files associated with the covert verb generation \n",
    "# (covertverbgeneration) task\n",
    "list_covertverbgen = layout.get(task='covertverbgeneration',\n",
    "                                extensions=['tsv','json'],\n",
    "                                return_type='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_covertverbgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a list of T1 weighted images from everybody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of T1w images from everybody\n",
    "listT1w = layout.get(type='T1w',\n",
    "                     extensions=['nii','nii.gz'],\n",
    "                     return_type='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listT1w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "1. **Even and odd lists**. Write a program to generate two lists of BOLD fMRI data (with `.nii.gz`) from the `ds102` data set; the first list contains the file names from even-numbered subjects, and the second list contains the file names from odd-numbered subjects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading meta data\n",
    "\n",
    "Using functionalities of `pybids`, we can read meta data associated with a BIDS data set. This is done by locating appropriate meta data files, and in case of JSON files, we can actually read meta data from files. \n",
    "\n",
    "### Reading participant information\n",
    "\n",
    "So, this is not exactly the application of `pybids`, as we use `pandas` to read a `.tsv` meta data file. However, we can locate the `participants.tsv` file using the **`get`** method for a BIDSLayout object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<ReadMetaData.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bids.grabbids import BIDSLayout\n",
    "\n",
    "# Directory where your data set resides. This needs to be customized.\n",
    "# For this exercise, we use ds102 data set\n",
    "dataDir = '/home/satoru/Teaching/fMRI_Fall_2018/Data/ds102'\n",
    "\n",
    "# Creating the layout objects \n",
    "layout = BIDSLayout(dataDir)\n",
    "\n",
    "\n",
    "# PARTICIPANT INFORMATION\n",
    "\n",
    "# reading in participant info (tsv read as pandas data frame)\n",
    "file_participants = layout.get(type='participants',\n",
    "                               extensions='tsv',\n",
    "                               return_type='file')[0]\n",
    "subjInfo = pd.read_csv(file_participants, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **What is a data frame?** A data frame typically contains observations with the same variables. So, conceptually it can be considered as a big table, where rows correspond to unique observations, and the columns correspond to variables. Data frames can be handled by using functions available in the **`pandas`** library. To access a particular column in the data frame, you need to specify the **data frame name**, a period (**`.`**), and the column name. Or, you can refer a column by specifying the column name, just like a library. For example, in the example, above, you can access the column **`age`** by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjInfo.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjInfo['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do a conditional indexing, similar to arrays. Since the order of observations is the same across columns, you can extract a collection of columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjInfo[subjInfo.gender=='D'][['participant_id','age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading image meta data\n",
    "\n",
    "There is a method called **`get_metadata`** that reads the meta data associated with an image data file. This method works even if the meta data file does not reside in the same directory as the image file, *as long as the inheritance principle is observed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<ReadMetaData.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images for sub-01\n",
    "listImages_sub01 = layout.get(subject='01',\n",
    "                              extensions=['nii', 'nii.gz'],\n",
    "                              return_type='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listImages_sub01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta data asccoiated with T1 weighted\n",
    "metaT1w = layout.get_metadata(listImages_sub01[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaT1w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This meta data file is not in the `anat` directory for this particular subject, but at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations of meta data files (T1w)\n",
    "metalocT1w = layout.get(type='T1w',\n",
    "                        extensions='json',\n",
    "                        return_type='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalocT1w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meta data file for an fMRI data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta data associated with fMRI (run1)\n",
    "metafMRI = layout.get_metadata(listImages_sub01[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metafMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the meta data are returned as a dictionary. So, you can specify a particular field as the key and you should be able to get the corresponding value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaT1w['ScanningSequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metafMRI['ScanningSequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metafMRI['RepetitionTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading task events data\n",
    "\n",
    "Task events are stored as a `.tsv` file. Thus, we can read task event information as a data frame, as we have seen earlier. To identify the task events data file, you can use the **`get`** method associated with the layout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<ReadMetaData.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task events tsv file for sub-01, run-1\n",
    "taskTSV = layout.get(subject='01',\n",
    "                     run='1',\n",
    "                     type='events',\n",
    "                     extensions='tsv',\n",
    "                     return_type='file')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskTSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the task info (as pandas data frame)\n",
    "taskInfo = pd.read_csv(taskTSV, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, we shall plot how the response time changes over the course of the experiment. In particular, we plot the event time on the x-axis and the response time on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun. Plotting the response time over experiment\n",
    "plt.plot(taskInfo[taskInfo.Stimulus=='incongruent'].onset,\n",
    "         taskInfo[taskInfo.Stimulus=='incongruent'].response_time,\n",
    "         'r.',\n",
    "         label='incongruent')\n",
    "plt.plot(taskInfo[taskInfo.Stimulus=='congruent'].onset,\n",
    "         taskInfo[taskInfo.Stimulus=='congruent'].response_time,\n",
    "         'b.',\n",
    "         label='congruent')\n",
    "plt.xlabel('Onset')\n",
    "plt.ylabel('Response time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "1. **Counting correct and incorrect**. Write a program to read the task event meta data file from a subject. The program then counts the number of correct responses and prints out the proportion of correct responses, separately for the congruent and incongruent conditions.\n",
    "2. **Average response time**. Write a program to read the task event meta data file from a subject. The program then calculates the average response time for the congruent and incongruent conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating paths\n",
    "\n",
    "You can use `pybids` to generate paths for directories and files that are compliant with the BIDS standard.\n",
    "\n",
    "### Building directory names\n",
    "Say, you want to add additional subjects to your BIDS data. You can create directories for the new subjects easily with `pybids`. Say you want to add 8 additional subjects (`11`, `12`, ..., `18`) to `ds114` data set. Then you can generate paths for the directories for these new subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<BuildPaths.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bids.grabbids import BIDSLayout\n",
    "\n",
    "# Directory where your data set resides. This needs to be customized.\n",
    "# For this exercise, lets use ds114 data set\n",
    "dataDir = '/home/satoru/Teaching/fMRI_Fall_2018/Data/ds114'\n",
    "\n",
    "# Creating the layout object for this BIDS data set\n",
    "layout = BIDSLayout(dataDir)\n",
    "\n",
    "# new subjects\n",
    "newSubj = list(range(10,19))\n",
    "\n",
    "# other information for the directory organization\n",
    "listSes = ['test', 'retest']\n",
    "listMod = ['anat', 'func', 'dwi']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, directories for the new subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, a list of new subject directories\n",
    "pattern = \"sub-{subject}\"\n",
    "for iSubj in newSubj:\n",
    "    # dictionary listing entitied\n",
    "    entities = {'subject':'%02d' % iSubj}\n",
    "    newDir = layout.build_path(entities, path_patterns=[pattern])\n",
    "    print(newDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, inside **`pattern`**, the field inside the curly brackets (**`subject`** in this case) was replaced by the value associated with the key `subject` inside a dictionary **`entities`**.\n",
    "\n",
    "For each subject, there should be session directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session directories for each subject\n",
    "pattern = \"sub-{subject}/ses-{session}\"\n",
    "for iSubj in newSubj:\n",
    "    for iSes in listSes:\n",
    "        # dictionary listing entitied\n",
    "        entities = {'subject':'%02d' % iSubj,\n",
    "                    'session':iSes}\n",
    "        newDir = layout.build_path(entities, path_patterns=[pattern])\n",
    "        print(newDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the dictionary `entities` have two keys, `subject` and `session`. The values corresponding to these keys are used to create paths.\n",
    "\n",
    "And different modalities for each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image modality directories for each subject\n",
    "pattern = \"sub-{subject}/ses-{session}/{modality}\"\n",
    "for iSubj in newSubj:\n",
    "    for iSes in listSes:\n",
    "        for iMod in listMod:\n",
    "            # dictionary listing entitied\n",
    "            entities = {'subject':'%02d' % iSubj,\n",
    "                        'session':iSes,\n",
    "                        'modality':iMod}\n",
    "            newDir = layout.build_path(entities, path_patterns=[pattern])\n",
    "            print(newDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am printing out directory names. If you want to create these directories, then you need to change the `print` function with `os.mkdir` function.\n",
    "\n",
    "You may notice that these paths are relative paths from the data set directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to change these paths to absolute paths, you need to add a new line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDir = os.path.join(layout.root, newDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building file names\n",
    "\n",
    "The same principle we used to create directory names can also be used to create file names. Say, we create all fMRI image data files for `sub-01`, `ses-test`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<BuildPaths.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bold fMRI data with different tasks\n",
    "listTask = ['covertverbgeneration',\n",
    "            'fingerfootlips',\n",
    "            'linebisection',\n",
    "            'overtverbgeneration',\n",
    "            'overtwordrepetition']\n",
    "pattern = \"sub-{subject}/ses-{session}/{modality}/sub-{subject}_ses-{session}_task-{task}_{type}.nii.gz\"\n",
    "for iTask in listTask:\n",
    "    entities = {'subject':'01',\n",
    "                'session':'test',\n",
    "                'modality':'func',\n",
    "                'task':iTask,\n",
    "                'type':'bold'}\n",
    "    newFile = layout.build_path(entities, path_patterns=[pattern])\n",
    "    print(newFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "1. **New tasks**. Say, you need to add new fMRI data to the `ds114` data set. The new data for each subject were acquired during two tasks (`nback` and `stroop`). These tasks were performed during both sessions but only by even-numbered subjects (`02`, `04`, ..., `18`). Generate a list of these new data files (`.nii.gz` file and the task event file `.tsv`), with an appropriate path originating from the data set directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
