{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:center'>\n",
    "PSY 394U <b>Methods for fMRI</b>, Fall 2018\n",
    "\n",
    "\n",
    "<img style='width: 300px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Placebo_Left.png?raw=true' alt='brain blobs'/>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style='text-align:center; font-size:40px; margin-bottom: 30px;'><b> First-level analysis </b></p>\n",
    "\n",
    "<p style='text-align:center; font-size:18px; margin-bottom: 32px;'><b> November 19, 2018</b></p>\n",
    "\n",
    "<hr style='height:5px;border:none' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-level analysis - theoretical background\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "The first-level analysis refers to a statistical analysis of fMRI data on a single subject (of a single session and/or a single run). The main goal in the first-level analysis is to fit a temporal model to the fMRI data to quantify the activation of interest as contrast(s). \n",
    "\n",
    "## Predicted BOLD signals\n",
    "Say, your fMRI experiement consists of epochs of baseline and stimulus.\n",
    "\n",
    "<img style='width: 400px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_ExperimentDesign.png?raw=true' alt='Experiment design'/>\n",
    "\n",
    "In this experiment, you anticipate activations associated with the stimulus, and you try to capture that with BOLD (blood oxygenation-level dependent) fMRI. However, after a neural activity, you can only observe delayed response in the resultant BOLD signal due to a hemodynamic delay. Such a delay is modeled by a function known as a **hemodynamic response function (HRF)**. The predicted BOLD signal, from an fMRI experiment, is the underlying neural activity convolved by an HRF.\n",
    "\n",
    "<img style='width: 700px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_BOLDSignal.png?raw=true' alt='Predicted BOLD signal'/>\n",
    "\n",
    "In most fMRI analysis software tools, you can generate boxcar signals for predicted neural activities simply by providing event onset times and durations. There are also a number of HRF models available for you to choose from. Your predicted neural response is convolved by the HRF of your choice, so you don't have to generate predicted BOLD fMRI signals by yourself.\n",
    "\n",
    "## High-pass filtering\n",
    "\n",
    "During an fMRI experiment, BOLD fMRI signals often fluctuates slowly, the phenomenon known as the **low-frequency drift**. \n",
    "\n",
    "<img style='width: 400px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_LowFreqDrift.png?raw=true' alt='Low frequency drift'/>\n",
    "\n",
    "This poses a challenge in statistical analyses of the data. Luckily low-frequency drift can be easily removed from fMRI data. Since it is low frequency, a high-pass filter can eliminate it. \n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_HighPass.png?raw=true' alt='High-pass filter before and after'/>\n",
    "\n",
    "A cut-off frequency of around 0.01Hz (or a period of 100s) seems to work well for typical fMRI data. \n",
    "\n",
    "\n",
    "## GLM\n",
    "\n",
    "GLM stands for **general linear model**. It is a statistical model that can be used for different types of analyses:\n",
    "  * ANOVA (analysis of variance): Comparison of group means\n",
    "  * ANCOVA (analysis of covariance): ANOVA adjusted for continuous variables\n",
    "  * Linear regression, simple & multiple\n",
    "  * T-test: Statistical test on mean(s)\n",
    "  * F-test: Statistical test to compare variances\n",
    "  \n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMSimple.png?raw=true' alt='GLM for simple regression'/>\n",
    "\n",
    "For your fMRI experiment data, you can fit such a model at each voxel separately.\n",
    "\n",
    "<img style='width: 400px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMSimple_fMRI.png?raw=true' alt='GLM for simple regression, fMRI'/>\n",
    "\n",
    "In this case, $\\beta$ parameters from all voxels collectively form a 3D image.\n",
    "\n",
    "In a more realistic case, there are more than one regressors in a GLM. \n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMMultiple.png?raw=true' alt='GLM for multiple regression'/>\n",
    "\n",
    "Or, using a matrix notation, one can describe this model with vectors:\n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMMultipleMatrix.png?raw=true' alt='GLM for multiple regression, matrix notation'/>\n",
    "\n",
    "In an fMRI experiment, a GLM with multiple regressors will result in multiple beta images.\n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_GLMMultiple_fMRI.png?raw=true' alt='GLM for multiple regression, fMRI experiment'/>\n",
    "\n",
    "### Notes on GLM for fMRI\n",
    "***fMRI time series is temporally correlated***\n",
    "   * Not independent data points. Violation in the assumptions of an ordinary regression model\n",
    "   \n",
    "***The temporal correlation needs to be addressed somehow***\n",
    "   * **Pre-whitenening**: Temporal correlation is minimized so that data points are almost independent. \n",
    "   * **Explicitly modeling temporal correlation**: The temporal correlation between neighboring time points is estimated, and used in the statistical model. \n",
    "\n",
    "***HRF is different in different parts of the brain***\n",
    "   * **Temporal derivatives** of the predicted BOLD signal can be included also included as regressors in the GLM\n",
    "   * Inclusion of temporal derivatives can correct delays in BOLD signals\n",
    "\n",
    "***Second line of difference against subject motion***\n",
    "   * The **rigid-body transformation parameters** from the motion correction step can be included as regressors in the GLM\n",
    "   * Any motion-associated fluctuation in BOLD fMRI can be corrected.\n",
    "\n",
    "   \n",
    "## Contrasts\n",
    "\n",
    "A contrast is a linear combination of regression parameters $\\beta$s. For example,\n",
    "\n",
    "  * $\\beta_1$: Activation associated with condition 1\n",
    "  * $-\\beta_2$: Deactivation associated with condition 2\n",
    "  * $\\beta_2-\\beta_1$: Activation difference between conditions 2 and 1. (Condition 2 > Condition 1)\n",
    "  * $\\beta_3-\\beta_1$: Activation difference between conditions 3 and 1. (Condition 3 > Condition 1)\n",
    "\n",
    "Or, using a vector notation, we can describe these contrasts as\n",
    "\n",
    "$$\n",
    "    \\beta_1 = \\begin{bmatrix}1 & 0 & 0 \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "           \\beta_{1} \\\\\n",
    "           \\beta_{2} \\\\\n",
    "           \\beta_{3}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    -\\beta_2 = \\begin{bmatrix}0 & -1 & 0 \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "           \\beta_{1} \\\\\n",
    "           \\beta_{2} \\\\\n",
    "           \\beta_{3}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\beta_2-\\beta_1 = \\begin{bmatrix}-1 & 1 & 0 \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "           \\beta_{1} \\\\\n",
    "           \\beta_{2} \\\\\n",
    "           \\beta_{3}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\beta_1+\\beta_2+\\beta_3 = \\begin{bmatrix}1 & 1 & 1 \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "           \\beta_{1} \\\\\n",
    "           \\beta_{2} \\\\\n",
    "           \\beta_{3}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In a first-level analysis, a contrast image can be calculated from beta-images. For example, then contrast $\\beta_2 - \\beta_1$ can be calculated as:\n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_ContrastImage.png?raw=true' alt='Contrast image example'/>\n",
    "\n",
    "Once the contrast image is generated, it is possible to perform a T-test (at each voxel separately) by calculating a T-statistic image. A T-statistic image can be calculated by dividing a contrast image by the residual standard error (SE) image, with an appropriate normalizing constant.\n",
    "\n",
    "<img style='width: 500px; padding: 0px;' src='https://github.com/sathayas/JupyterfMRIFall2018/blob/master/Images/Level1_TStatImage.png?raw=true' alt='T-statistic image calculation'/>\n",
    "\n",
    "In fMRI data analysis, the directionality matters. Highly positive T-statistics are associated with activations or effects described in the contrast. Highly negative T-statistics, on the other hand, represent deactivations or  negative effects.\n",
    "\n",
    "### Omnibus testing with an F-contrast\n",
    "\n",
    "Say, you are interested in the difference among any of 3 conditions. In other words, you want to examine:\n",
    "  * $\\beta_3 - \\beta_2$ (contrast vector [0 -1 1])\n",
    "  * $\\beta_3 - \\beta_1$ (contrast vector [-1 0 1])\n",
    "  * $\\beta_2 - \\beta_1$ (contrast vector [-1 1 0])\n",
    "\n",
    "You can examine each of these separately by a t-test. Or, you can examine these together collectively using an **F-contrast**. An F-contrast can be written as a matrix. In this particular example, the contrast is described by stacking the contrasts into a matrix.\n",
    "\n",
    "$$\n",
    "        \\begin{bmatrix}\n",
    "           0 & -1 & 1 \\\\\n",
    "           -1 & 0 & 1 \\\\\n",
    "           -1 & 1 & 0 \n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If you are interested in an F-contrast, an F-contrast image as well as an F-statistic image can be calculated (details not shown). An F-statistic is non-directional. Thus a significantly large F-statistic may mean either activation or deactivation (or positive or negative differences), but the directionality cannot be determined by an F-statistic alone. Moreover, it is hard to determine which comparison contributed to the significant F-test outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-level analysis - FSL approach\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<Level1_fsl.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bids/grabbids/__init__.py:6: FutureWarning: grabbids has been renamed to layout in version 0.6.5, and will be removed in version 0.8\n",
      "  warnings.warn(\"grabbids has been renamed to layout in version 0.6.5, and will be removed in version 0.8\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import nibabel as nib   # nibabel to read TR from image header\n",
    "import nipype.interfaces.fsl as fsl # importing FSL interface functions\n",
    "from nipype import Node, Workflow  # components to construct workflow\n",
    "from nipype.interfaces.io import DataSink  # datasink\n",
    "from nipype.algorithms import modelgen  # GLM model generator\n",
    "from nipype.interfaces.base import Bunch\n",
    "from bids.grabbids import BIDSLayout  # BIDSLayout object to specify file(s)\n",
    "\n",
    "\n",
    "# data directory\n",
    "dataDir = '/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114'\n",
    "\n",
    "# base directory - where preprocessed fMRI data is located\n",
    "baseDir = os.path.join(dataDir, 'WorkflowOutput/FSL_Preproc_fMRI')\n",
    "\n",
    "# Creating the layout object for this BIDS data set\n",
    "layout = BIDSLayout(dataDir)\n",
    "\n",
    "# pre-processed fMRI data\n",
    "imagefMRI = os.path.join(baseDir,\n",
    "                         'sub-09_ses-test_task-fingerfootlips_bold_roi_mcf_warp_smooth_masked.nii.gz')\n",
    "\n",
    "# task information file\n",
    "eventFile = layout.get(type='events',\n",
    "                       task='fingerfootlips',\n",
    "                       extensions='tsv',\n",
    "                       return_type='file')[0]\n",
    "\n",
    "\n",
    "# Output directory\n",
    "outDir = os.path.join(dataDir,'WorkflowOutput')\n",
    "\n",
    "# getting TR from the image header\n",
    "fMRI = nib.load(imagefMRI)   # image object\n",
    "hdr_fMRI = fMRI.header\n",
    "TR = hdr_fMRI['pixdim'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting experiment info from the event file, into a Bunch object\n",
    "trialInfo = pd.read_table(eventFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>weight</th>\n",
       "      <th>trial_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Finger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Foot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Finger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Foot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>160</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>190</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Finger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>220</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Foot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>280</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Finger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>310</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Foot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>340</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>370</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Finger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>400</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Foot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>430</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lips</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    onset  duration  weight trial_type\n",
       "0      10      15.0       1     Finger\n",
       "1      40      15.0       1       Foot\n",
       "2      70      15.0       1       Lips\n",
       "3     100      15.0       1     Finger\n",
       "4     130      15.0       1       Foot\n",
       "5     160      15.0       1       Lips\n",
       "6     190      15.0       1     Finger\n",
       "7     220      15.0       1       Foot\n",
       "8     250      15.0       1       Lips\n",
       "9     280      15.0       1     Finger\n",
       "10    310      15.0       1       Foot\n",
       "11    340      15.0       1       Lips\n",
       "12    370      15.0       1     Finger\n",
       "13    400      15.0       1       Foot\n",
       "14    430      15.0       1       Lips"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trialInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of conditions\n",
    "conditions = sorted(list(set(trialInfo.trial_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finger', 'Foot', 'Lips']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting onset and duration information\n",
    "onsets = []\n",
    "durations = []\n",
    "\n",
    "for itrial in conditions:\n",
    "    onsets.append(list(trialInfo[trialInfo.trial_type==itrial].onset-10)) # subtracting 10s due to removing of 4 dummy scans\n",
    "    durations.append(list(trialInfo[trialInfo.trial_type==itrial].duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 90, 180, 270, 360], [30, 120, 210, 300, 390], [60, 150, 240, 330, 420]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15.0, 15.0, 15.0, 15.0, 15.0],\n",
       " [15.0, 15.0, 15.0, 15.0, 15.0],\n",
       " [15.0, 15.0, 15.0, 15.0, 15.0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidation these lists into a single Bunch object\n",
    "subject_info = [Bunch(conditions=conditions,\n",
    "                      onsets=onsets,\n",
    "                      durations=durations,\n",
    "                      )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bunch(conditions=['Finger', 'Foot', 'Lips'],\n",
       "       durations=[[15.0, 15.0, 15.0, 15.0, 15.0],\n",
       "        [15.0, 15.0, 15.0, 15.0, 15.0],\n",
       "        [15.0, 15.0, 15.0, 15.0, 15.0]],\n",
       "       onsets=[[0, 90, 180, 270, 360],\n",
       "        [30, 120, 210, 300, 390],\n",
       "        [60, 150, 240, 330, 420]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining contrasts\n",
    "cont01 = ['average',        'T', conditions, [1/3., 1/3., 1/3.]]\n",
    "cont02 = ['Finger',         'T', conditions, [1, 0, 0]]\n",
    "cont03 = ['Foot',           'T', conditions, [0, 1, 0]]\n",
    "cont04 = ['Lips',           'T', conditions, [0, 0, 1]]\n",
    "cont05 = ['Finger > others','T', conditions, [1, -0.5, -0.5]]\n",
    "cont06 = ['Foot > others',  'T', conditions, [-0.5, 1, -0.5]]\n",
    "cont07 = ['Lips > others',  'T', conditions, [-0.5, -0.5, 1]]\n",
    "\n",
    "cont08 = ['activation',     'F', [cont02, cont03, cont04]]\n",
    "\n",
    "contrast_list = [cont01, cont02, cont03, cont04, cont05, cont06, cont07, cont08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['average',\n",
       "  'T',\n",
       "  ['Finger', 'Foot', 'Lips'],\n",
       "  [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]],\n",
       " ['Finger', 'T', ['Finger', 'Foot', 'Lips'], [1, 0, 0]],\n",
       " ['Foot', 'T', ['Finger', 'Foot', 'Lips'], [0, 1, 0]],\n",
       " ['Lips', 'T', ['Finger', 'Foot', 'Lips'], [0, 0, 1]],\n",
       " ['Finger > others', 'T', ['Finger', 'Foot', 'Lips'], [1, -0.5, -0.5]],\n",
       " ['Foot > others', 'T', ['Finger', 'Foot', 'Lips'], [-0.5, 1, -0.5]],\n",
       " ['Lips > others', 'T', ['Finger', 'Foot', 'Lips'], [-0.5, -0.5, 1]],\n",
       " ['activation',\n",
       "  'F',\n",
       "  [['Finger', 'T', ['Finger', 'Foot', 'Lips'], [1, 0, 0]],\n",
       "   ['Foot', 'T', ['Finger', 'Foot', 'Lips'], [0, 1, 0]],\n",
       "   ['Lips', 'T', ['Finger', 'Foot', 'Lips'], [0, 0, 1]]]]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specification\n",
    "modelspec = Node(modelgen.SpecifyModel(functional_runs=imagefMRI,\n",
    "                                       subject_info=subject_info,\n",
    "                                       input_units='secs',\n",
    "                                       time_repetition=TR,\n",
    "                                       high_pass_filter_cutoff=100),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# first-level design\n",
    "level1design = Node(fsl.Level1Design(bases={'dgamma':{'derivs': True}},\n",
    "                                     interscan_interval=TR,\n",
    "                                     model_serial_correlations=True,\n",
    "                                     contrasts=contrast_list),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# creating all the other files necessary to run the model\n",
    "modelgen = Node(fsl.FEATModel(),\n",
    "                name='modelgen')\n",
    "\n",
    "# then running through FEAT\n",
    "feat = Node(fsl.FEAT(),\n",
    "            name=\"feat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating datasink to collect outputs\n",
    "datasink = Node(DataSink(base_directory=outDir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the workflow\n",
    "firstLevel = Workflow(name=\"Level1_FSL\", base_dir=outDir)\n",
    "\n",
    "# connecting nodes\n",
    "firstLevel.connect([(modelspec, level1design, [('session_info', 'session_info')])])\n",
    "firstLevel.connect([(level1design, modelgen, [('fsf_files', 'fsf_file'),\n",
    "                                              ('ev_files','ev_files')])])\n",
    "firstLevel.connect([(level1design, feat, [('fsf_files', 'fsf_file')])])\n",
    "firstLevel.connect([(feat, datasink, [('feat_dir', 'FSL_Level1.@feat')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181119-14:28:53,909 nipype.workflow INFO:\n",
      "\t Workflow Level1_FSL settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "181119-14:28:53,919 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "181119-14:28:53,920 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_FSL.modelspec\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_FSL/modelspec\".\n",
      "181119-14:28:53,924 nipype.workflow INFO:\n",
      "\t [Node] Cached \"Level1_FSL.modelspec\" - collecting precomputed outputs\n",
      "181119-14:28:53,926 nipype.workflow INFO:\n",
      "\t [Node] \"Level1_FSL.modelspec\" found cached.\n",
      "181119-14:28:53,927 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_FSL.level1design\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_FSL/level1design\".\n",
      "181119-14:28:53,934 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"Level1_FSL.level1design\".\n",
      "181119-14:28:53,942 nipype.workflow INFO:\n",
      "\t [Node] Running \"level1design\" (\"nipype.interfaces.fsl.model.Level1Design\")\n",
      "181119-14:28:53,959 nipype.workflow INFO:\n",
      "\t [Node] Finished \"Level1_FSL.level1design\".\n",
      "181119-14:28:53,960 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_FSL.feat\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_FSL/feat\".\n",
      "181119-14:28:53,963 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"Level1_FSL.feat\".\n",
      "181119-14:28:54,21 nipype.workflow INFO:\n",
      "\t [Node] Running \"feat\" (\"nipype.interfaces.fsl.model.FEAT\"), a CommandLine Interface with command:\n",
      "feat /Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_FSL/level1design/run0.fsf\n",
      "181119-14:28:55,107 nipype.interface INFO:\n",
      "\t stdout 2018-11-19T14:28:55.107412:To view the FEAT progress and final report, point your web browser at /Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_FSL/feat/run0.feat/report_log.html\n",
      "Outputs from FEATmodel: {'feat_dir': '/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_FSL/feat/run0.feat'}\n",
      "181119-14:40:24,641 nipype.workflow INFO:\n",
      "\t [Node] Finished \"Level1_FSL.feat\".\n",
      "181119-14:40:24,642 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_FSL.datasink\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_FSL/datasink\".\n",
      "181119-14:40:24,650 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasink\" (\"nipype.interfaces.io.DataSink\")\n",
      "181119-14:40:28,551 nipype.workflow INFO:\n",
      "\t [Node] Finished \"Level1_FSL.datasink\".\n",
      "181119-14:40:28,553 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_FSL.modelgen\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_FSL/modelgen\".\n",
      "181119-14:40:28,558 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"Level1_FSL.modelgen\".\n",
      "181119-14:40:28,567 nipype.workflow INFO:\n",
      "\t [Node] Running \"modelgen\" (\"nipype.interfaces.fsl.model.FEATModel\"), a CommandLine Interface with command:\n",
      "feat_model run0 \n",
      "181119-14:40:29,434 nipype.workflow INFO:\n",
      "\t [Node] Finished \"Level1_FSL.modelgen\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x10fc36c50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the workflow\n",
    "firstLevel.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-level analysis - SPM approach\n",
    "<hr style=\"height:1px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<Level1_spm.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bids/grabbids/__init__.py:6: FutureWarning: grabbids has been renamed to layout in version 0.6.5, and will be removed in version 0.8\n",
      "  warnings.warn(\"grabbids has been renamed to layout in version 0.6.5, and will be removed in version 0.8\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import nibabel as nib   # nibabel to read TR from image header\n",
    "import nipype.interfaces.spm as spm # importing SPM interface functions\n",
    "from nipype import Node, Workflow  # components to construct workflow\n",
    "from nipype.interfaces.io import DataSink  # datasink\n",
    "from nipype.algorithms import modelgen  # GLM model generator\n",
    "from nipype.interfaces.base import Bunch\n",
    "from bids.grabbids import BIDSLayout  # BIDSLayout object to specify file(s)\n",
    "\n",
    "# getting info where matlab is located\n",
    "matlabDir = subprocess.run(['which', 'matlab'], stdout=subprocess.PIPE)\n",
    "matlabCmd = matlabDir.stdout.strip().decode('utf-8')\n",
    "spm.SPMCommand.set_mlab_paths(matlab_cmd=matlabCmd)\n",
    "\n",
    "# data directory\n",
    "dataDir = '/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114'\n",
    "\n",
    "# base directory - where preprocessed fMRI data is located\n",
    "baseDir = os.path.join(dataDir, 'WorkflowOutput/SPM_Preproc_fMRI')\n",
    "\n",
    "# Creating the layout object for this BIDS data set\n",
    "layout = BIDSLayout(dataDir)\n",
    "\n",
    "# pre-processed fMRI data\n",
    "imagefMRI = os.path.join(baseDir,\n",
    "                         'swrsub-09_ses-test_task-fingerfootlips_bold.nii')\n",
    "\n",
    "# task information file\n",
    "eventFile = layout.get(type='events',\n",
    "                       task='fingerfootlips',\n",
    "                       extensions='tsv',\n",
    "                       return_type='file')[0]\n",
    "\n",
    "# brain mask image\n",
    "#imageMask = '/usr/local/spm12/tpm/TPM.nii'\n",
    "imageMask = '/Users/sh45474/SoftwareTools/spm12/tpm/mask_ICV.nii'\n",
    "\n",
    "# Output directory\n",
    "outDir = os.path.join(dataDir,'WorkflowOutput')\n",
    "\n",
    "# TR for the fMRI time series\n",
    "TR = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting experiment info from the event file, into a Bunch object\n",
    "trialInfo = pd.read_table(eventFile)\n",
    "conditions = sorted(list(set(trialInfo.trial_type)))\n",
    "onsets = []\n",
    "durations = []\n",
    "\n",
    "for itrial in conditions:\n",
    "    onsets.append(list(trialInfo[trialInfo.trial_type==itrial].onset)) \n",
    "    durations.append(list(trialInfo[trialInfo.trial_type==itrial].duration))\n",
    "\n",
    "subject_info = [Bunch(conditions=conditions,\n",
    "                      onsets=onsets,\n",
    "                      durations=durations,\n",
    "                      )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bunch(conditions=['Finger', 'Foot', 'Lips'],\n",
       "       durations=[[15.0, 15.0, 15.0, 15.0, 15.0],\n",
       "        [15.0, 15.0, 15.0, 15.0, 15.0],\n",
       "        [15.0, 15.0, 15.0, 15.0, 15.0]],\n",
       "       onsets=[[10, 100, 190, 280, 370],\n",
       "        [40, 130, 220, 310, 400],\n",
       "        [70, 160, 250, 340, 430]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining contrasts\n",
    "cont01 = ['average',        'T', conditions, [1/3., 1/3., 1/3.]]\n",
    "cont02 = ['Finger',         'T', conditions, [1, 0, 0]]\n",
    "cont03 = ['Foot',           'T', conditions, [0, 1, 0]]\n",
    "cont04 = ['Lips',           'T', conditions, [0, 0, 1]]\n",
    "cont05 = ['Finger > others','T', conditions, [1, -0.5, -0.5]]\n",
    "cont06 = ['Foot > others',  'T', conditions, [-0.5, 1, -0.5]]\n",
    "cont07 = ['Lips > others',  'T', conditions, [-0.5, -0.5, 1]]\n",
    "\n",
    "cont08 = ['activation',     'F', [cont02, cont03, cont04]]\n",
    "\n",
    "contrast_list = [cont01, cont02, cont03, cont04, cont05, cont06, cont07, cont08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the model\n",
    "modelspec = Node(modelgen.SpecifySPMModel(functional_runs=imagefMRI,\n",
    "                                          input_units='secs',\n",
    "                                          output_units='secs',\n",
    "                                          time_repetition=TR,\n",
    "                                          high_pass_filter_cutoff=100,\n",
    "                                          subject_info=subject_info),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# First-level model\n",
    "level1design = Node(spm.Level1Design(bases={'hrf': {'derivs': [1, 0]}},\n",
    "                                     timing_units='secs',\n",
    "                                     interscan_interval=TR,\n",
    "                                     model_serial_correlations='AR(1)',\n",
    "                                     mask_image=imageMask),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# EstimateModel - estimate the parameters of the model\n",
    "level1estimate = Node(spm.EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      name=\"level1estimate\")\n",
    "\n",
    "# EstimateContrast - estimates contrasts\n",
    "level1conest = Node(spm.EstimateContrast(contrasts=contrast_list),\n",
    "                    name=\"level1conest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating datasink to collect outputs\n",
    "datasink = Node(DataSink(base_directory=outDir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiation of the 1st-level analysis workflow\n",
    "l1analysis = Workflow(name='Level1_SPM', base_dir=outDir)\n",
    "\n",
    "\n",
    "# Connect up the 1st-level analysis components\n",
    "l1analysis.connect([(modelspec, level1design, [('session_info','session_info')]),\n",
    "                    (level1design, level1estimate, [('spm_mat_file','spm_mat_file')]),\n",
    "                    (level1estimate, level1conest, [('spm_mat_file','spm_mat_file'),\n",
    "                                                    ('beta_images','beta_images'),\n",
    "                                                    ('residual_image','residual_image')]),\n",
    "                    (level1conest, datasink, [('spm_mat_file', 'SPM_Level1.@spm_mat'),\n",
    "                                              ('spmT_images', 'SPM_Level1.@T'),\n",
    "                                              ('con_images', 'SPM_Level1.@con'),\n",
    "                                              ('spmF_images', 'SPM_Level1.@F'),\n",
    "                                              ('ess_images', 'SPM_Level1.@ess'),\n",
    "                                              ]),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181120-22:09:11,906 nipype.workflow INFO:\n",
      "\t Workflow Level1_SPM settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "181120-22:09:11,920 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "181120-22:09:11,921 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_SPM.modelspec\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_SPM/modelspec\".\n",
      "181120-22:09:11,927 nipype.workflow INFO:\n",
      "\t [Node] Cached \"Level1_SPM.modelspec\" - collecting precomputed outputs\n",
      "181120-22:09:11,929 nipype.workflow INFO:\n",
      "\t [Node] \"Level1_SPM.modelspec\" found cached.\n",
      "181120-22:09:11,930 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_SPM.level1design\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_SPM/level1design\".\n",
      "181120-22:09:11,936 nipype.workflow INFO:\n",
      "\t [Node] Cached \"Level1_SPM.level1design\" - collecting precomputed outputs\n",
      "181120-22:09:11,937 nipype.workflow INFO:\n",
      "\t [Node] \"Level1_SPM.level1design\" found cached.\n",
      "181120-22:09:11,939 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_SPM.level1estimate\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_SPM/level1estimate\".\n",
      "181120-22:09:11,946 nipype.workflow INFO:\n",
      "\t [Node] Cached \"Level1_SPM.level1estimate\" - collecting precomputed outputs\n",
      "181120-22:09:11,947 nipype.workflow INFO:\n",
      "\t [Node] \"Level1_SPM.level1estimate\" found cached.\n",
      "181120-22:09:11,948 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_SPM.level1conest\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_SPM/level1conest\".\n",
      "181120-22:09:11,960 nipype.workflow INFO:\n",
      "\t [Node] Cached \"Level1_SPM.level1conest\" - collecting precomputed outputs\n",
      "181120-22:09:11,961 nipype.workflow INFO:\n",
      "\t [Node] \"Level1_SPM.level1conest\" found cached.\n",
      "181120-22:09:11,962 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"Level1_SPM.datasink\" in \"/Users/sh45474/Documents/Teaching/fMRI_Fall_2018/Data/ds114/WorkflowOutput/Level1_SPM/datasink\".\n",
      "181120-22:09:11,977 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasink\" (\"nipype.interfaces.io.DataSink\")\n",
      "181120-22:09:11,993 nipype.workflow INFO:\n",
      "\t [Node] Finished \"Level1_SPM.datasink\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x10e31ef60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the workflow\n",
    "l1analysis.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review design and contrasts in SPM GUI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "**First-level workflow, `ds102`**. Write a program with a workflow for the first-level analysis for the `ds102` you processed for your Homework Assignment 4. You may choose either `run1` or `run2`. Post the code on Canvas.\n",
    "\n",
    "***Hints:***\n",
    "  1. *Consider 'congruent' and 'incongruent' (in the **`Stimulus`** column) as the two conditions in this experiment.*\n",
    "  2. *Consider the following contrasts:*\n",
    "     1. Congruent\n",
    "     2. Incongruent\n",
    "     3. Congruent > Incongruent\n",
    "     4. Incongruent > Congruent\n",
    "     5. Average of congruent & incongruent\n",
    "  3. *Depending on your fMRI preprocessing workflow, it is necessary to adjust the onset time if you deleted the first 4 dummy scans. Note that the TR is different in this experiment (2.0s), consequently the onset adjustment is different.*\n",
    "  4. *If the onset time needs to be adjusted, you may not be able to model the first event in the experiment since the onset time (unadjusted) is 0s. If that is the case, the first event needs to be deleted in your subject_info.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the results\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "* Compare contrast images from SPM and FSL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
